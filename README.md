Advancements in End-to-End Audio Style Transformation: A Differentiable Approach for Voice Conversion and Musical Style Transfer
This is an article accepted by MDPI AI 2025 for publishing (Preprints ID: preprints-138667), authored by Shashwat Aggarwal, Shashwat Uttam, Sameer Garg, Shubham Garg, Kopal Jain and Swati Aggarwal.
Keywords: Voice Conversion; Musical Style Transfer; Audio Transformations; End-to-End Audio Pipeline

We introduce a fully differentiable end-to-end audio transformation network designed to convert the style of one audio sample to another. 
This method offers three significant advantages: 
(a) it operates without the need for parallel utterances, transcriptions, or time alignment processes
(b) it utilizes a global conditioning mechanism, making it vocabulary agnostic and capable of transforming audio styles regardless of the target identity
(c) it performs one-shot audio transformations without intermediate phonetic representations

This eliminates the necessity for phonetic alignments and speaker-independent ASR networks. 
We assess our method against existing approaches in voice conversion and musical style transfer tasks. Subjective evaluations demonstrate the superiority of our approach. 
The network employs an encoder-decoder architecture that integrates neural network models known for their explainability in Natural Language Processing tasks.
